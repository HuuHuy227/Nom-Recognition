{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport re,string\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom typing import Iterable, List\nfrom gensim.models import KeyedVectors\nfrom torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.nn import Transformer\nfrom torch.nn.utils.rnn import pad_sequence\nfrom timeit import default_timer as timer\nimport math\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:29.599224Z","iopub.execute_input":"2023-02-10T12:44:29.599695Z","iopub.status.idle":"2023-02-10T12:44:29.609703Z","shell.execute_reply.started":"2023-02-10T12:44:29.599652Z","shell.execute_reply":"2023-02-10T12:44:29.608413Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nomvitranslate/nom-vi (1).csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:29.611920Z","iopub.execute_input":"2023-02-10T12:44:29.612751Z","iopub.status.idle":"2023-02-10T12:44:29.890534Z","shell.execute_reply.started":"2023-02-10T12:44:29.612713Z","shell.execute_reply":"2023-02-10T12:44:29.889576Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(62503, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"This dataset provides a set of 254,090 tuples containing an English source sentence, its Vietnamese human translation and we take 170000 set for training and evaluation","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:29.894924Z","iopub.execute_input":"2023-02-10T12:44:29.897235Z","iopub.status.idle":"2023-02-10T12:44:29.919511Z","shell.execute_reply.started":"2023-02-10T12:44:29.897196Z","shell.execute_reply":"2023-02-10T12:44:29.918430Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"nom    62\nvi      2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Drop nan \ndf = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:29.923870Z","iopub.execute_input":"2023-02-10T12:44:29.926125Z","iopub.status.idle":"2023-02-10T12:44:29.950737Z","shell.execute_reply.started":"2023-02-10T12:44:29.926088Z","shell.execute_reply":"2023-02-10T12:44:29.949740Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def preprocessing(df): \n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation)))  \n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.lower())\n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: ele.strip()) \n  df[\"vi\"] = df[\"vi\"].apply(lambda ele: re.sub(\"\\s+\", \" \", ele))\n    \n  return df\n\ndf = preprocessing(df)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:29.956936Z","iopub.execute_input":"2023-02-10T12:44:29.959222Z","iopub.status.idle":"2023-02-10T12:44:31.458717Z","shell.execute_reply.started":"2023-02-10T12:44:29.959183Z","shell.execute_reply":"2023-02-10T12:44:31.457355Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"            nom                                                 vi\n0            膿㺧                                           nọng heo\n1       扽檜𤽗𡗉𩵜伵鮮                     đòn củi ngươi nhiều cá tớ tươi\n2       帝皆不問獨命勘                      đế giai bất vấn độc mệnh khám\n3       董鼎箕埃𩧍㗂持                   đủng đỉnh kìa ai ruổi tiếng chày\n4  香兔沉沁海若茹蛟豸俸蟾宫  hương thỏ chìm tăm hải nhược nhà giao giãi bón...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nom</th>\n      <th>vi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>膿㺧</td>\n      <td>nọng heo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>扽檜𤽗𡗉𩵜伵鮮</td>\n      <td>đòn củi ngươi nhiều cá tớ tươi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>帝皆不問獨命勘</td>\n      <td>đế giai bất vấn độc mệnh khám</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>董鼎箕埃𩧍㗂持</td>\n      <td>đủng đỉnh kìa ai ruổi tiếng chày</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>香兔沉沁海若茹蛟豸俸蟾宫</td>\n      <td>hương thỏ chìm tăm hải nhược nhà giao giãi bón...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Tokenzing for english which is source language by tokenizer of basic english and vietnamese which is target language by Underthesea library","metadata":{}},{"cell_type":"code","source":"# Create source and target language tokenizer.\nSRC_LANGUAGE = 'nom'\nTGT_LANGUAGE = 'vi'\n\n# Place-holders\ntoken_transform = {}\nvocab_transform = {}\n\n# Tokenize for nom\ndef nom_tokenizer(sentence):\n    return [*sentence]\n\n# Tokenize for vietnames\ndef vi_tokenizer(sentence):\n    return sentence.split()\n\ntoken_transform[SRC_LANGUAGE] = get_tokenizer(nom_tokenizer)\ntoken_transform[TGT_LANGUAGE] = get_tokenizer(vi_tokenizer)\n\n# helper function to yield list of tokens\ndef yield_tokens(data_iter: Iterable, language: str) -> List[str]:    \n    for index,data_sample in data_iter:\n        yield token_transform[language](data_sample[language])\n\n# Define special symbols and indices\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    # Training data Iterator\n    train_iter = df.iterrows()\n    # Create torchtext's Vocab object\n    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n                                                    min_freq=1,\n                                                    specials=special_symbols,\n                                                    special_first=True)\n\n# Set UNK_IDX as the default index. This index is returned when the token is not found.\n# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n  vocab_transform[ln].set_default_index(UNK_IDX)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:31.460865Z","iopub.execute_input":"2023-02-10T12:44:31.461727Z","iopub.status.idle":"2023-02-10T12:44:40.707565Z","shell.execute_reply.started":"2023-02-10T12:44:31.461689Z","shell.execute_reply":"2023-02-10T12:44:40.706052Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# def save_vocab(vocab,path):\n#     import pickle\n#     output = open(path, 'wb')\n#     pickle.dump(vocab, output)\n#     output.close()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:40.709303Z","iopub.execute_input":"2023-02-10T12:44:40.710014Z","iopub.status.idle":"2023-02-10T12:44:40.714407Z","shell.execute_reply.started":"2023-02-10T12:44:40.709974Z","shell.execute_reply":"2023-02-10T12:44:40.713427Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# save_vocab(vocab_transform[SRC_LANGUAGE],'vocab_src.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:40.716146Z","iopub.execute_input":"2023-02-10T12:44:40.716953Z","iopub.status.idle":"2023-02-10T12:44:40.729921Z","shell.execute_reply.started":"2023-02-10T12:44:40.716917Z","shell.execute_reply":"2023-02-10T12:44:40.728778Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Model Defination","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Check whether running on gpu or cpu\n\n# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float = 0.1,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        \n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size) \n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor,\n                memory_key_padding_mask: Tensor):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n   \n    def encode(self, src: Tensor, src_mask: Tensor):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:40.732608Z","iopub.execute_input":"2023-02-10T12:44:40.733478Z","iopub.status.idle":"2023-02-10T12:44:40.753409Z","shell.execute_reply.started":"2023-02-10T12:44:40.733382Z","shell.execute_reply":"2023-02-10T12:44:40.751465Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt):\n    src_seq_len = src.shape[0]\n    tgt_seq_len = tgt.shape[0]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n\n    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:40.754908Z","iopub.execute_input":"2023-02-10T12:44:40.755317Z","iopub.status.idle":"2023-02-10T12:44:40.767867Z","shell.execute_reply.started":"2023-02-10T12:44:40.755283Z","shell.execute_reply":"2023-02-10T12:44:40.766449Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Define the parameters of the model, instantiate the same and the loss function which is the cross-entropy loss and the optmizer used for training is Adam with β1 = 0.9, β2 = 0.98 and epsilon = 1e−9.","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\nSRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\nTGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\nEMB_SIZE = 256\nNHEAD = 4 # embed_dim must be divisible by num_heads\nFFN_HID_DIM = 256\nBATCH_SIZE = 64\nNUM_ENCODER_LAYERS = 3\nNUM_DECODER_LAYERS = 3\nDROP_OUT = 0.1\n\ntransformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)\n\nfor p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)\n\ntransformer = transformer.to(DEVICE)\n\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n\noptimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:40.769187Z","iopub.execute_input":"2023-02-10T12:44:40.770176Z","iopub.status.idle":"2023-02-10T12:44:41.026587Z","shell.execute_reply.started":"2023-02-10T12:44:40.770142Z","shell.execute_reply":"2023-02-10T12:44:41.025042Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Define collate function that convert batch of raw strings into batch tensors that can be fed directly into model.","metadata":{}},{"cell_type":"code","source":"# helper function to club together sequential operations\ndef sequential_transforms(*transforms):\n    def func(txt_input):\n        for transform in transforms:\n            txt_input = transform(txt_input)\n        return txt_input\n    return func\n\n# function to add BOS/EOS and create tensor for input sequence indices\ndef tensor_transform(token_ids: List[int]):\n    return torch.cat((torch.tensor([BOS_IDX]),\n                      torch.tensor(token_ids),\n                      torch.tensor([EOS_IDX])))\n\n# src and tgt language text transforms to convert raw strings into tensors indices\ntext_transform = {}\nfor ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n                                               vocab_transform[ln], #Numericalization\n                                               tensor_transform) # Add BOS/EOS and create tensor\n\n\n\n     \n# function to collate data samples into batch tesors\ndef collate_fn(batch):\n    src_batch, tgt_batch = [], []\n    \n    for src_sample, tgt_sample in batch:\n        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n\n    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n    return src_batch, tgt_batch","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:41.028200Z","iopub.execute_input":"2023-02-10T12:44:41.028577Z","iopub.status.idle":"2023-02-10T12:44:41.057948Z","shell.execute_reply.started":"2023-02-10T12:44:41.028535Z","shell.execute_reply":"2023-02-10T12:44:41.056803Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Split data to train and test set","metadata":{}},{"cell_type":"code","source":"# Split data to tran test set\nsplit_ratio = 0.9\nsplit = round(df.shape[0]* split_ratio)\ntrain = df.iloc[:split]\ntrain_ds = list(zip(train['nom'],train['vi']))\nvalid = df.iloc[split:]\nval_ds = list(zip(valid['nom'],valid['vi']))","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:41.060286Z","iopub.execute_input":"2023-02-10T12:44:41.061244Z","iopub.status.idle":"2023-02-10T12:44:41.106726Z","shell.execute_reply.started":"2023-02-10T12:44:41.061206Z","shell.execute_reply":"2023-02-10T12:44:41.105561Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Define training and evaluation loop that will be called for each epoch with Gradient accumulation which is a technique where you can train on bigger batch sizes than your machine would normally be able to fit into memory. This is done by accumulating gradients over several batches, and only stepping the optimizer after a certain number of batches have been performed.","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, optimizer):\n    model.train()\n    losses = 0\n    val_los = 0\n    train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n     \n    for src, tgt in tqdm(train_dataloader, leave=False):\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)   \n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n        \n        optimizer.zero_grad()\n        \n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        loss.backward()\n\n        optimizer.step() \n        losses += loss.item()\n\n    return losses / len(train_dataloader)\n\ndef evaluate(model):\n    model.eval()\n    losses = 0\n\n    #val_iter = valid.iterrows()\n    val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n\n    for src, tgt in val_dataloader:\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        losses += loss.item()\n\n    return losses / len(val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:41.111274Z","iopub.execute_input":"2023-02-10T12:44:41.111900Z","iopub.status.idle":"2023-02-10T12:44:41.125103Z","shell.execute_reply.started":"2023-02-10T12:44:41.111860Z","shell.execute_reply":"2023-02-10T12:44:41.124159Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Define an early stopping function to avoid the model from overfit","metadata":{}},{"cell_type":"code","source":"class EarlyStopping():\n    def __init__(self, tolerance=5, min_delta=0):\n\n        self.tolerance = tolerance\n        self.min_delta = min_delta\n        self.counter = 0\n        self.early_stop = False\n\n    def __call__(self, train_loss, validation_loss):\n        if (validation_loss - train_loss) > self.min_delta:\n            self.counter +=1\n            if self.counter >= self.tolerance:  \n                self.early_stop = True","metadata":{"execution":{"iopub.status.busy":"2023-02-10T12:44:41.126479Z","iopub.execute_input":"2023-02-10T12:44:41.127046Z","iopub.status.idle":"2023-02-10T12:44:41.138779Z","shell.execute_reply.started":"2023-02-10T12:44:41.127005Z","shell.execute_reply":"2023-02-10T12:44:41.137920Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Training model","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(tolerance=5, min_delta=0.1)\nNUM_EPOCHS = 50\nhistory = {\n        \"loss\": [], \n        \"val_los\": []\n        }\nbest_valid_loss = float('inf')\nvalid_every = 5\n\nfor epoch in range(1, NUM_EPOCHS+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer)\n    end_time = timer()\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n    if epoch % valid_every == 0:\n        val_loss = evaluate(transformer)\n        if val_loss < best_valid_loss:\n            best_valid_loss = val_loss\n            save_model_path = os.path.join('./checkpoint/',f'train_loss{val_loss}.pt')\n            path, _ = os.path.split(save_model_path)\n            os.makedirs(path, exist_ok=True)\n            torch.save(transformer.state_dict(), save_model_path)\n        print((f\"Val loss: {val_loss:.3f}\"))\n        history['val_los'].append(val_loss)\n    history['loss'].append(train_loss)\n    \n    # Early Stopping\n#     early_stopping(train_loss, val_loss)\n#     if early_stopping.early_stop:\n#         print(\"We are at epoch:\", epoch)\n#         break","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-02-10T12:44:41.140321Z","iopub.execute_input":"2023-02-10T12:44:41.140901Z","iopub.status.idle":"2023-02-10T13:20:20.748926Z","shell.execute_reply.started":"2023-02-10T12:44:41.140865Z","shell.execute_reply":"2023-02-10T13:20:20.747875Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Train loss: 6.607, Epoch time = 42.701s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Train loss: 4.980, Epoch time = 42.408s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Train loss: 2.852, Epoch time = 42.427s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Train loss: 1.796, Epoch time = 42.523s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Train loss: 1.339, Epoch time = 42.390s\nVal loss: 1.197\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Train loss: 1.099, Epoch time = 42.628s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 7, Train loss: 0.946, Epoch time = 42.675s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 8, Train loss: 0.838, Epoch time = 42.199s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 9, Train loss: 0.754, Epoch time = 42.306s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Train loss: 0.685, Epoch time = 42.532s\nVal loss: 0.836\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 11, Train loss: 0.627, Epoch time = 42.476s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 12, Train loss: 0.576, Epoch time = 42.298s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 13, Train loss: 0.534, Epoch time = 42.590s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 14, Train loss: 0.495, Epoch time = 42.355s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 15, Train loss: 0.462, Epoch time = 42.304s\nVal loss: 0.719\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 16, Train loss: 0.430, Epoch time = 42.455s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 17, Train loss: 0.404, Epoch time = 42.574s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 18, Train loss: 0.379, Epoch time = 42.488s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 19, Train loss: 0.355, Epoch time = 42.416s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 20, Train loss: 0.334, Epoch time = 42.404s\nVal loss: 0.659\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 21, Train loss: 0.313, Epoch time = 42.499s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 22, Train loss: 0.296, Epoch time = 42.360s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 23, Train loss: 0.279, Epoch time = 42.406s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 24, Train loss: 0.264, Epoch time = 42.646s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 25, Train loss: 0.249, Epoch time = 42.404s\nVal loss: 0.620\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 26, Train loss: 0.236, Epoch time = 42.329s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 27, Train loss: 0.224, Epoch time = 42.475s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 28, Train loss: 0.212, Epoch time = 42.619s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 29, Train loss: 0.202, Epoch time = 42.254s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 30, Train loss: 0.191, Epoch time = 42.566s\nVal loss: 0.622\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 31, Train loss: 0.183, Epoch time = 42.365s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 32, Train loss: 0.172, Epoch time = 42.779s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 33, Train loss: 0.164, Epoch time = 42.399s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 34, Train loss: 0.156, Epoch time = 42.512s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 35, Train loss: 0.149, Epoch time = 42.511s\nVal loss: 0.637\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 36, Train loss: 0.141, Epoch time = 42.309s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 37, Train loss: 0.135, Epoch time = 42.394s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 38, Train loss: 0.127, Epoch time = 42.622s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 39, Train loss: 0.122, Epoch time = 42.648s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 40, Train loss: 0.116, Epoch time = 42.312s\nVal loss: 0.647\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 41, Train loss: 0.111, Epoch time = 43.054s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 42, Train loss: 0.106, Epoch time = 42.338s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 43, Train loss: 0.101, Epoch time = 42.357s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 44, Train loss: 0.096, Epoch time = 42.533s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 45, Train loss: 0.092, Epoch time = 42.622s\nVal loss: 0.650\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 46, Train loss: 0.088, Epoch time = 42.549s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 47, Train loss: 0.085, Epoch time = 42.759s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 48, Train loss: 0.081, Epoch time = 42.275s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 49, Train loss: 0.078, Epoch time = 42.518s\n","output_type":"stream"},{"name":"stderr","text":"                                                 \r","output_type":"stream"},{"name":"stdout","text":"Epoch: 50, Train loss: 0.075, Epoch time = 42.505s\nVal loss: 0.633\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Traning and Validate plotting","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history['loss'], label = \"loss\")\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss vs. No. of epochs');","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-10T13:20:20.750762Z","iopub.execute_input":"2023-02-10T13:20:20.751140Z","iopub.status.idle":"2023-02-10T13:20:20.959025Z","shell.execute_reply.started":"2023-02-10T13:20:20.751101Z","shell.execute_reply":"2023-02-10T13:20:20.958047Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**Inference**","metadata":{}},{"cell_type":"code","source":"# function to generate output sequence using greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    src = src.to(DEVICE)\n    src_mask = src_mask.to(DEVICE)\n\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n    for i in range(max_len-1):\n        memory = memory.to(DEVICE)\n        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n                    .type(torch.bool)).to(DEVICE)\n        out = model.decode(ys, memory, tgt_mask)\n        out = out.transpose(0, 1)\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n        if next_word == EOS_IDX:\n            break\n    return ys\n\n\n# actual function to translate input sentence into target language\ndef translate(model: torch.nn.Module, src_sentence: str):\n    model.eval()\n    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n    num_tokens = src.shape[0]\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n    tgt_tokens = greedy_decode(\n        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")","metadata":{"execution":{"iopub.status.busy":"2023-02-10T13:20:20.960589Z","iopub.execute_input":"2023-02-10T13:20:20.961179Z","iopub.status.idle":"2023-02-10T13:20:20.972234Z","shell.execute_reply.started":"2023-02-10T13:20:20.961139Z","shell.execute_reply":"2023-02-10T13:20:20.971275Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"translate(transformer, '身㛪辰𤽸分㛪𧷺')","metadata":{"execution":{"iopub.status.busy":"2023-02-10T13:23:44.006044Z","iopub.execute_input":"2023-02-10T13:23:44.006427Z","iopub.status.idle":"2023-02-10T13:23:44.048415Z","shell.execute_reply.started":"2023-02-10T13:23:44.006392Z","shell.execute_reply":"2023-02-10T13:23:44.047245Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"' thân em thì trắng phận em tròn '"},"metadata":{}}]},{"cell_type":"code","source":"# Saving model\ntorch.save(transformer.state_dict(), \"transformer_pretrained.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-02-10T13:20:21.026650Z","iopub.execute_input":"2023-02-10T13:20:21.027002Z","iopub.status.idle":"2023-02-10T13:20:21.230687Z","shell.execute_reply.started":"2023-02-10T13:20:21.026967Z","shell.execute_reply":"2023-02-10T13:20:21.229664Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Testing model by randomly take 10 samples from the rest of the dataset","metadata":{}},{"cell_type":"code","source":"from random import randint\nrand = [randint(0,6169) for i in range(10)]\ntest_set = [\n        [valid.iloc[i]['nom'] for i in rand],\n        [valid.iloc[i]['vi'] for i in rand]]\n    \nfor i in range(len(test_set[0])):\n    print('Input:', test_set[0][i])\n    print('Actual Translation:', test_set[1][i])\n    print('Predicted Translation:', translate(transformer, test_set[0][i]))\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-02-10T13:20:21.232552Z","iopub.execute_input":"2023-02-10T13:20:21.232964Z","iopub.status.idle":"2023-02-10T13:20:21.550291Z","shell.execute_reply.started":"2023-02-10T13:20:21.232926Z","shell.execute_reply":"2023-02-10T13:20:21.549256Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Input: 鮮肉舌𫪹哉\nActual Translation: tiên nhục thịt sống còn tươi\nPredicted Translation:  tiên nhục thịt sống tai \n\n\nInput: 帝出據州城即龍編也\nActual Translation: đế xuất cứ châu thành tức long biên dã\nPredicted Translation:  đế xuất cứ châu thành tức long biên dã \n\n\nInput: 源恩箕空蕯麻潙\nActual Translation: nguồn ơn kia không tát mà vơi\nPredicted Translation:  nguồn ân kia không tát mà vơi \n\n\nInput: 掬制春泣每頽\nActual Translation: cuốc chơi xuân khắp mọi đồi\nPredicted Translation:  cuốc chơi xuân khắp mọi đồi \n\n\nInput: 大牙𫆢丐於歌边含\nActual Translation: đại nha răng cái ở ca bên hàm\nPredicted Translation:  đại nha răng cái ở ca bên hàm \n\n\nInput: 娘浪隻栢㳥濤\nActual Translation: nàng rằng chiếc bách sóng đào\nPredicted Translation:  nàng rằng chiếc bách sóng đào \n\n\nInput: 三月令各衙門吏鄕試中式除正官\nActual Translation: tam nguyệt lệnh các nha môn lại hương thí trúng thức trừ chính quan\nPredicted Translation:  tam nguyệt lệnh các nha môn lại hương thí trúng thức trừ chính quan \n\n\nInput: 爫𠊚𢪀善等冲𡎝𠊚\nActual Translation: làm người nghĩ thẹn đứng trong cõi người\nPredicted Translation:  làm người nghĩ thiện đấng trong cõi người \n\n\nInput: 瓊𧗱㮔全穭吳。\nActual Translation: quỳnh về trồng toàn lúa ngô\nPredicted Translation:  quỳnh về trồng toàn lúa ngô lai \n\n\nInput: 箕文君媚苗課𫏾\nActual Translation: kìa văn quân mỹ miều thuở trước\nPredicted Translation:  kìa văn quân mỵ miều thuở trước \n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**References**\n\nhttps://pytorch.org/tutorials/beginner/translation_transformer.html","metadata":{}}]}